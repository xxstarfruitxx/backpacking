{
    "name_en": "English",
    "name_local": "English",
    "keys":
    {
        "\n                            The \"Utilities\" tab provides a variety of general utilities and tools in the subtabs above, and the quicktools below.\n                        ": "",
        "\n                            This is a tool to analyze CLIP tokenization for Stable Diffusion models.\n                            All current Stable Diffusion models use the same CLIP token set, so this applies to them all.\n                            Simply type some text in the box below to see how it gets tokenized.\n                            It will show each text-piece, and its numerical ID.\n                        ": "",
        "\n                            This is a tool to extract a LoRA from the difference between two models.\n                            \"Base\" should be whatever the common base model is, eg SDXL-1.0-Base.\n                            \"Other\" should be the unique model with information to extract into the LoRA.\n                            The closer Base is to Other, the less complex the LoRA's data will be, and the more likely it will work well with other models that were built off the same base.\n                            \n                            Note that LoRA Extraction is an imperfect partial process, and will lose some of the data that makes the model unique.\n                            Rank is a number indicating how much detail to try to save. Higher numbers result in bigger files, and only slightly more accurate matching. Small values (eg 16) are usually sufficient.\n                        ": "",
        "\n                            This is a tool to quickle convert legacy Pickle (.pt, .ckpt, .bin) files to modern Safetensors files.\n                            WARNING: Pickle files may contain malicious code. Do not use this tool or otherwise load pickle files unless you trust their source.\n                            The pickle files will be moved to a \"backups\" folder, and the safetensors files left in place where the pickles originally were.\n                            You may delete the backups folder after confirming the new safetensors files work as intended.\n                            Be aware that this may temporarily use a large amount of filespace.\n                            This may take some time to process.\n                            (You can continue using the UI as normal while this runs)\n                        ": "",
        "\n                            TypeCountConvert\n                        ": "",
        "\n                (TODO: info n stuff here)\n                \n            ": "",
        "...": "",
        "(For API usage) If enabled, requests preview output from ControlNet and no image generation at all.": "",
        "[AutoWebUI] Sampler": "",
        "[Close]\n                    ": "",
        "[ComfyUI] Custom Workflow": "",
        "[ComfyUI] Workflow": "",
        "[DT] CFG Scale Minimum": "",
        "[DT] CFG Scale Mode": "",
        "[DT] Interpolate Phi": "",
        "[DT] Mimic Scale": "",
        "[DT] Mimic Scale Minimum": "",
        "[DT] Mimic Scale Mode": "",
        "[DT] Scaling Startpoint": "",
        "[DT] Scheduler Value": "",
        "[DT] Separate Feature Channels": "",
        "[DT] Threshold Percentile": "",
        "[DT] Variability Measure": "",
        "[Dynamic Thresholding]\n'phi' interpolation factor.\nInterpolates between original value and DT value, such that 0.0 = use original, and 1.0 = use DT.\n(This exists because RCFG is bad and so half-removing it un-breaks it - better to just not do RCFG).": "",
        "[Dynamic Thresholding]\nCFG Scale minimum value (for non-constant CFG mode).": "",
        "[Dynamic Thresholding]\nIf either scale scheduler is 'Power', this is the power factor.\nIf using 'repeating', this is the number of repeats per image. Otherwise, it does nothing.": "",
        "[Dynamic Thresholding]\nMimic Scale minimum value (for non-constant mimic mode).": "",
        "[Dynamic Thresholding]\nMimic Scale value (target for the CFG Scale recentering).": "",
        "[Dynamic Thresholding]\nMode for the CFG Scale scheduler.": "",
        "[Dynamic Thresholding]\nMode for the Mimic Scale scheduler.": "",
        "[Dynamic Thresholding]\nthresholding percentile. '1' disables, '0.95' is decent value for enabled.": "",
        "[Dynamic Thresholding]\nWhether to scale relative to the mean value or to zero.\nUse 'MEAN' normally. If you want RCFG logic, use 'ZERO'.": "",
        "[Dynamic Thresholding]\nWhether to separate the feature channels.\nNormally leave this on. I think it should be off for RCFG?": "",
        "[Dynamic Thresholding]\nWhether to use standard deviation ('STD') or thresholded absolute values ('AD').\nNormally use 'AD'. Use 'STD' if wanting RCFG logic.": "",
        "[FreeU] Apply To": "",
        "[FreeU] Block One": "",
        "[FreeU] Block Two": "",
        "[FreeU] Skip One": "",
        "[FreeU] Skip Two": "",
        "[Grid Gen] Presets": "",
        "[Grid Gen] Prompt Replace": "",
        "[Internal] Backend Type": "",
        "[SAPI] Engine": "",
        "[SAPI] Sampler": "",
        "a cartoonish drawing of an astronaut": "",
        "a photo of a cat": "",
        "Address": "",
        "Admin": "",
        "Advanced Model Addons": "",
        "Advanced Sampling": "",
        "Allow Reordering": "",
        "AllowedModels": "",
        "AllowedSettings": "",
        "AllowIdle": "",
        "Alt Resolution Height Multiplier": "",
        "Alternate Steps value for the refiner stage.": "",
        "AppendUserNameToOutputPath": "",
        "Apply parameter presets to the image. Can use a comma-separated list to apply multiple per-cell, eg 'a, b || a, c || b, c'": "",
        "Aspect Ratio": "",
        "Auto Swap To Previews": "",
        "Auto WebUI": "",
        "Automatic Scorer": "",
        "AutoUpdate": "",
        "Backends": "",
        "Backends are automatically assigned unique ports. This value selects which port number to start the assignment from.\nDefault is '7820'.": "",
        "BackendStartingPort": "",
        "Batch Size": "",
        "Batch size - generates more images at once on a single GPU.\nThis increases VRAM usage.\nMay in some cases increase overall speed by a small amount (runs slower to get the images, but slightly faster per-image).": "",
        "Big Cards": "",
        "Big Thumbnails": "",
        "Block1 multiplier value for FreeU.\nPaper recommends 1.1.": "",
        "Block2 multiplier value for FreeU.\nPaper recommends 1.2.": "",
        "Blur-sigma for Self-Attention Guidance.\nDefaults to 2.0.": "",
        "Builder for output file paths. Can use auto-filling placeholders like '[model]' for the model name, '[prompt]' for a snippet of prompt text, etc.\nFull details in the docs: https://github.com/Stability-AI/StableSwarmUI/blob/master/docs/User%20Settings.md#path-format": "",
        "Cancel": "",
        "CanChangeModels": "",
        "Cards": "",
        "CFG Scale": "",
        "Clear Batch": "",
        "Clear Images": "",
        "ClearSystemRAMAfterMinutes": "",
        "ClearVRAMAfterMinutes": "",
        "CLIP Stop At Layer": "",
        "CLIP Tokenization": "",
        "CLIP Tokenizer": "",
        "Close": "",
        "Comfy Workflow Editor": "",
        "ComfyUI": "",
        "ComfyUI Advanced": "",
        "Continue On Error": "",
        "ControlNet": "",
        "ControlNet End": "",
        "ControlNet Image Input": "",
        "ControlNet Model": "",
        "ControlNet Preprocessor": "",
        "ControlNet Preview Only": "",
        "ControlNet Start": "",
        "ControlNet Strength": "",
        "ControlNets": "",
        "Convert ControlNets": "",
        "Convert Embeddings": "",
        "Convert LoRAs": "",
        "Convert Models": "",
        "Convert to FP16?": "",
        "Convert VAEs": "",
        "Core Parameters": "",
        "Create New Preset: ": "",
        "Current LoRAs: ": "",
        "Current presets": "",
        "DataPath": "",
        "Debug Regional Prompting": "",
        "Default settings for users (unless the user modifies them, if so permitted).\n<br>(NOTE: Usually, don't edit this. Go to the 'User' tab to edit your User-Settings).": "",
        "DefaultSDv1VAE": "",
        "DefaultSDXLVAE": "",
        "DefaultUser": "",
        "DefaultUserRestriction": "",
        "Delay, in seconds, betweeen Generate Forever updates.\nIf the delay hits and a generation is still waiting, it will be skipped.\nDefault is 0.1 seconds.": "",
        "Delete Preset": "",
        "Depth of subfolders to show": "",
        "DisableInternalArgs": "",
        "Display Advanced Options?": "",
        "Display Normally-Hidden Options?": "",
        "Do Not Save": "",
        "Download": "",
        "DPI": "",
        "Dry Run": "",
        "Dynamic Thresholding": "",
        "Edit Model Metadata: ": "",
        "Edit Preset": "",
        "Edit Wildcard: ": "",
        "Embeddings": "",
        "Enable AITemplate": "",
        "Enable/disable image": "",
        "EnablePreviews": "",
        "End Steps Early": "",
        "Engine for StabilityAPI to use.": "",
        "Error": "",
        "Exact Backend ID": "",
        "Examples": "",
        "Export Presets": "",
        "ExtraArgs": "",
        "Extract LoRA": "",
        "Failed to get session ID after 3 tries. Your account may have been invalidated. Try refreshing the page, or contact the site owner.": "",
        "Failed to get WebSocket address. You may be connecting to the server in an unexpected way. Please use \"http\" or \"https\" URLs.": "",
        "Failed to send request to server. Did the server crash?": "",
        "Fast Skip": "",
        "FileFormat": "",
        "Folder path for image output.\nIt is highly recommended that this is an empty folder.": "",
        "Folder path for input images.\nThis folder should contain a non-recursive single layer of image files (png/jpg).": "",
        "Format": "",
        "Free Memory": "",
        "FreeU": "",
        "Generate": "",
        "Generate Forever": "",
        "Generate Page": "",
        "Generate Previews": "",
        "GenerateForeverDelay": "",
        "Generic permission flags. '*' means all.\nDefault is all.": "",
        "Giant Thumbnails": "",
        "Global Region Factor": "",
        "Go back up 1 folder": "",
        "GPU_ID": "",
        "Grid Generator: Load Modal": "",
        "Height": "",
        "Higher values give the refiner more control, lower values give the base more control.\nThis is similar to 'Init Image Creativity', but for the refiner. This controls how many steps the refiner takes.": "",
        "Higher values make the ControlNet apply more strongly. Weaker values let the prompt overrule the ControlNet.": "",
        "Higher values make the generation more creative, lower values follow the init image closer.\nSometimes referred to as 'Denoising Strength' for 'img2img'.": "",
        "HintFormat": "",
        "Host": "",
        "How long any one part can be.\nDefault is 40 characters.": "",
        "How long to wait (in seconds) after all queues are done before sending the queue end webhook.\nThis is useful to prevent rapid start+end calls.": "",
        "How many directories deep a user's custom OutPath can be.\nDefault is 5.": "",
        "How many frames to generate within the video.": "",
        "How many images can try to be generating at the same time on this user.": "",
        "How many images the history view should stop trying to load after.": "",
        "How many images to generate at once.": "",
        "How many minutes to wait after the last generation before automatically freeing up system RAM (to prevent issues with other programs).\nThis has the downside of causing models to fully load from data drive at next usage.\nUse a decimal number to free after seconds.\nDefaults to 60 minutes (one hour).": "",
        "How many minutes to wait after the last generation before automatically freeing up VRAM (to prevent issues with other programs).\nThis has the downside of a small added bit of time to load back onto VRAM at next usage.\nUse a decimal number to free after seconds.\nDefaults to 10 minutes.": "",
        "How many steps to use for the video model.\nHigher step counts yield better quality, but much longer generation time.\n20 is a good baseline.": "",
        "How many times to retry initializing a backend before giving up. Default is 3.": "",
        "How many times to run the model.\nMore steps = better quality, but more time.\n20 is a good baseline for speed, 40 is good for maximizing quality.\nYou can go much higher, but it quickly becomes pointless above 70 or so.": "",
        "How much noise to add to the init image.\nHigher values yield more motion.": "",
        "How strong to apply ReVision image inputs.\nSet to 0 to disable ReVision processing.": "",
        "How strongly to apply the variation seed.\n0 = don't use, 1 = replace the base seed entirely. 0.5 is a good value.": "",
        "How strongly to scale prompt input.\nHigher CFG scales tend to produce more contrast, and lower CFG scales produce less contrast.\nToo-high values can cause corrupted/burnt images, too-low can cause nonsensical images.\n7 is a good baseline. Normal usages vary between 5 and 9.": "",
        "How to apply the refiner. Different methods create different results.\n'PostApply' runs the base in full, then runs the refiner with an Init Image.\n'StepSwap' swaps the model after x steps during generation.\n'StepSwapNoisy' is StepSwap but with first-stage noise only.": "",
        "How to display previews for generating videos.\n'Animate' shows a low-res animated video preview.\n'iterate' shows one frame at a time while it goes.\n'one' displays just the first frame.\n'none' disables previews.": "",
        "How to launch the UI. If 'none', just quietly launch.\nIf 'web', launch your web-browser to the page.\nIf 'webinstall', launch web-browser to the install page.\nIf 'electron', launch the UI in an electron window (NOT YET IMPLEMENTED).": "",
        "How to upscale the image, if upscaling is used.": "",
        "If checked, enables AITemplate for ComfyUI generations (UNet only). Only compatible with some GPUs.": "",
        "If checked, outputs masks from regional prompting for debug reasons.": "",
        "If checked, tells the server that previews are not desired.\nMay make generations slightly faster in some cases.": "",
        "If checked, tells the server to not save this image.\nUseful for quick test generations, or 'generate forever' usage.": "",
        "If checked, the seed will not be incremented when Images is above 1.\nUseful for example to test different wildcards for the same seed rapidly.": "",
        "If enabled, automatically clears out the image batch when generating a new one. If disabled, leaves history to grow until you refresh the page.": "",
        "If enabled, automatically swaps to previews of new images the moment they're available, before the image itself is done generating.": "",
        "If enabled, batch size will be reset to 1 when parameters are loaded.\nThis can prevent accidents that might thrash your GPU or cause compatibility issues, especially for example when importing a comfy workflow.\nYou can still set the batch size at will in the GUI.": "",
        "If enabled, decodes images through the VAE using tiles of this size.\nVAE Tiling reduces VRAM consumption, but takes longer and may impact quality.": "",
        "If enabled, feeds this prompt to an unsampler before resampling with your main prompt.\nThis is powerful for controlled image editing.": "",
        "If enabled, removes the background from the generated image.\nThis uses RemBG.": "",
        "If enabled, saves a copy of the image before the refiner stage.": "",
        "If set to non-0, adds DPI metadata to saved images.\n'72' is a good value for compatibility with some external software.": "",
        "If set to true, a '.txt' file will be saved alongside images with the image metadata easily viewable.\nThis can work even if saving in the image is disabled. Defaults disabled.": "",
        "If this is set to 'true', hides the installer page. If 'false', the installer page will be shown.": "",
        "If true, folders will be discard from starred image paths.": "",
        "If true, if the port is already in use, the server will try to find another port to use instead.\nIf false, the server will fail to start if the port is already in use.": "",
        "If true, the Image History view will cache small preview thumbnails of images.\nThis should make things run faster. You can turn it off if you don't want that.": "",
        "If true, the user is treated as a full admin.\nThis includes the ability to modify these settings.": "",
        "If true, user may load models.\nIf false, they may only use already-loaded models.": "",
        "Image aspect ratio. Some models can stretch better than others.": "",
        "Image height, in pixels.\nSDv1 uses 512, SDv2 uses 768, SDXL prefers 1024.\nSome models allow variation within a range (eg 512 to 768) but almost always want a multiple of 64.": "",
        "Image History": "",
        "Image seed.\n-1 = random.\nDifferent seeds produce different results for the same prompt.": "",
        "Image width, in pixels.\nSDv1 uses 512, SDv2 uses 768, SDXL prefers 1024.\nSome models allow variation within a range (eg 512 to 768) but almost always want a multiple of 64.": "",
        "Image-variation seed.\nCombined partially with the original seed to create a similar-but-different image for the same seed.\n-1 = random.": "",
        "ImageFormat": "",
        "ImageHistoryUsePreviews": "",
        "Images": "",
        "Images to include with the prompt, for eg ReVision or UnCLIP.\nIf this parameter is visible, you've done something wrong - this parameter is tracked internally.": "",
        "Implements 'FreeU: Free Lunch in Diffusion U-Net' https://arxiv.org/abs/2309.11497": "",
        "Import": "",
        "Import Presets": "",
        "Info": "",
        "Init Image": "",
        "Init Image Creativity": "",
        "Init Image Reset To Norm": "",
        "Init-image, to edit an image using diffusion.\nThis process is sometimes called 'img2img' or 'Image To Image'.": "",
        "Input Folder": "",
        "Interrupt All Sessions": "",
        "Interrupt Current Session": "",
        "IP-Adapter Weight": "",
        "IsInstalled": "",
        "Language": "",
        "LaunchMode": "",
        "Like the input prompt text, but describe what NOT to generate.\nTell the AI things you don't want to see.": "",
        "List": "",
        "Local Network": "",
        "LogLevel": "",
        "Logs": "",
        "LoRA Extractor": "",
        "LoRA Weights": "",
        "LoRAs": "",
        "LoRAs (Low-Rank-Adaptation Models) are a way to customize the content of a model without totally replacing it.\nYou can enable one or several LoRAs over top of one model.": "",
        "lowres, low quality": "",
        "Makes the generated image seamlessly tileable (like a 3D texture would be).": "",
        "Manually force a specific exact backend (by ID #) to be used for this generation.": "",
        "Mask Image": "",
        "Mask-image, white pixels are changed, black pixels are not changed, gray pixels are half-changed.": "",
        "MaxBackendInitAttempts": "",
        "MaxImagesInHistory": "",
        "MaxImagesInMiniGrid": "",
        "Maximum sigma value for the sampler.\nOnly applies to Karras/Exponential schedulers.": "",
        "MaxLenPerPart": "",
        "MaxOutPathDepth": "",
        "MaxRequestsForcedOrder": "",
        "MaxSimulPreviews": "",
        "MaxT2ISimultaneous": "",
        "MaxTimeoutMinutes": "",
        "Merges the init image towards the latent norm.\nThis essentially lets you boost 'init image creativity' past 1.0.\nSet to 0 to disable.": "",
        "Metadata Reset": "",
        "Minimum sigma value for the sampler.\nOnly applies to Karras/Exponential schedulers.": "",
        "Missing Preview Preset": "",
        "Model": "",
        "Model Author": "",
        "Model Date": "",
        "Model description text...": "",
        "Model License": "",
        "Model Merged From": "",
        "Model Tags": "",
        "Model Trigger Phrase": "",
        "Model Type": "",
        "Model Usage Hint": "",
        "ModelRoot": "",
        "Models": "",
        "Negative Prompt": "",
        "Network": "",
        "No Previews": "",
        "No Seed Increment": "",
        "Notice: this is raw internal configuration of parameters. Don't mess with this unless you know what you're doing.": "",
        "NvidiaQueryRateLimitMS": "",
        "Only keep images with a generated score above this minimum.": "",
        "Only keep the best *this many* images in a batch based on scoring.\n(For example, if batch size = 8, and this value = 2, then 8 images will generate and will be scored, and the 2 best will be kept and the other 6 discarded.)": "",
        "Open Empty Image Editor": "",
        "Optional field to type in any personal text note you want.\nThis will be stored in the image metadata.": "",
        "Optional upscale of the image between the base and refiner stage.\nSometimes referred to as 'high-res fix'.\nSetting to '1' disables the upscale.": "",
        "Optional VAE replacement for the refiner stage.": "",
        "Optionally specify a (raw HTML) welcome message here. If specified, will override the automatic welcome messages.": "",
        "Options to override default VAEs with.": "",
        "OutPathBuilder": "",
        "Output Folder": "",
        "Output Folder Name": "",
        "Output folder name...": "",
        "OutputPath": "",
        "OverQueue": "",
        "OverrideWelcomeMessage": "",
        "Overwrite Existing Files": "",
        "Overwrite existing presets": "",
        "Parameter Configuration": "",
        "Parameters in the Preset": "",
        "Paths": "",
        "Percentage of steps to cut off before the image is done generation.": "",
        "PermissionFlags": "",
        "PerRequestTimeoutMinutes": "",
        "Personal Note": "",
        "Pickle To Safetensors": "",
        "Port": "",
        "PortCanChange": "",
        "Prefix a line with # to make it a comment (ie won't be counted as an option).": "",
        "Preset description text...": "",
        "Presets": "",
        "Prompt": "",
        "Prompt Images": "",
        "Prompt only CSV": "",
        "Publish Generation Metadata": "",
        "QueueEndDelay": "",
        "QueueEndWebhook": "",
        "QueueStartWebhook": "",
        "Quick Tools": "",
        "Ratelimit, in milliseconds, between Nvidia GPU status queries. Default is 1000 ms (1 second).": "",
        "Refiner": "",
        "Refiner Control Percentage": "",
        "Refiner HyperTile": "",
        "Refiner Method": "",
        "Refiner Model": "",
        "Refiner Save Before Refine": "",
        "Refiner Steps": "",
        "Refiner Upscale": "",
        "Refiner Upscale Method": "",
        "Refiner VAE": "",
        "Refresh": "",
        "Regional Object Inpainting Model": "",
        "Regional Prompting": "",
        "Reload Parameter Values": "",
        "Remove Background": "",
        "Replace text in the prompt (or negative prompt) with some other text.": "",
        "Reset All Metadata": "",
        "Reset Page Layout": "",
        "Reset Params to Default": "",
        "ResetBatchSizeToOne": "",
        "Reshow Welcome Message": "",
        "Resolution": "",
        "Resolution, eg 1024x1024": "",
        "Resource Usage": "",
        "Restart All Backends": "",
        "Restrictions to apply to default users.": "",
        "ReVision": "",
        "ReVision Model": "",
        "ReVision Strength": "",
        "ReVision Zero Prompt": "",
        "Rho value for the sampler.\nOnly applies to Karras/Exponential schedulers.": "",
        "Root path for data (user configs, etc).\nDefaults to 'Data'": "",
        "Root path for model files. Use a full-formed path (starting with '/' or a Windows drive like 'C:') to use an absolute path.\nDefaults to 'Models'.": "",
        "Root path for output files (images, etc).\nDefaults to 'Output'": "",
        "Safety check, the maximum duration all requests can be waiting for a backend before the system declares a backend handling failure.": "",
        "Sampler": "",
        "Sampler for StabilityAPI to use.": "",
        "Sampler Rho": "",
        "Sampler Sigma Max": "",
        "Sampler Sigma Min": "",
        "Sampler type (for AutoWebUI)": "",
        "Sampler type (for ComfyUI)": "",
        "Save": "",
        "SaveFiles": "",
        "SaveMetadata": "",
        "SaveTextFileMetadata": "",
        "Scale for Self-Attention Guidance.\n''Self-Attention Guidance (SAG) uses the intermediate self-attention maps of diffusion models to enhance their stability and efficacy.\nSpecifically, SAG adversarially blurs only the regions that diffusion models attend to at each iteration and guides them accordingly.''\nDefaults to 0.5.": "",
        "Scheduler": "",
        "Scheduler type (for ComfyUI)": "",
        "Score Must Exceed": "",
        "Scoring": "",
        "Scoring engine(s) to use when scoring this image. Multiple scorers can be used and will be averaged together. Scores are saved in image metadata.": "",
        "SDClipVisionFolder": "",
        "SDControlNetsFolder": "",
        "SDEmbeddingFolder": "",
        "SDLoraFolder": "",
        "SDModelFolder": "",
        "SDVAEFolder": "",
        "Seamless Tileable": "",
        "Seed": "",
        "Select the checkbox next to inputs you want included in the preset.By default this will override values entirely. For text inputs, use {value} to include the current UI value instead of overriding.": "",
        "Self-Attention Guidance Scale": "",
        "Self-Attention Guidance Sigma Blur": "",
        "Server": "",
        "Server Configuration": "",
        "Server Info": "",
        "Set to a number above 1 to allow generations of multiple images to automatically generate square mini-grids when they're done.": "",
        "Settings related to backends.": "",
        "Settings related to file paths.": "",
        "Settings related to networking and the webserver.": "",
        "Settings related to output path building.": "",
        "Settings related to saved file format.": "",
        "Settings related to the User Interface.": "",
        "Settings related to webhooks.": "",
        "Show Advanced Backend Types": "",
        "Show Prompt Tokenization": "",
        "Shutdown": "",
        "Skip1 multiplier value for FreeU.\nPaper recommends 0.9.": "",
        "Skip2 multiplier value for FreeU.\nPaper recommends 0.2.": "",
        "Small Cards": "",
        "Small Thumbnails": "",
        "StabilityAPI": "",
        "StableSwarmUI JSON": "",
        "StarNoFolders": "",
        "Start Anyway": "",
        "Start generating images\nRight-click for advanced options.": "",
        "StartScript": "",
        "Steps": "",
        "Swarm Internal": "",
        "Take Best N Score": "",
        "Tell the AI what you want to see, then press Enter to submit.\nConsider 'a photo of a cat', or 'cartoonish drawing of an astronaut'": "",
        "Test Again": "",
        "Test Wildcard: ": "",
        "Text filter, only show items that contain this text.": "",
        "The CFG Scale to use for video generation.\nVideos start with this CFG on the first frame, and then reduce to MinCFG (normally 1) by the end frame.\nSVD-XT 0.9 normally uses 25 frames, and SVD (non-XT) 0.9 uses 14 frames.": "",
        "The CLIP Vision model folder to use within 'ModelRoot'.\nDefaults to 'clip_vision'.\nAbsolute paths work too.": "",
        "The CLIP Vision model to use for ReVision inputs.\nThis will also override IPAdapter (if IPAdapter-G is in use).": "",
        "The ControlNet model to use.": "",
        "The ControlNets model folder to use within 'ModelRoot'.\nDefaults to 'controlnet'.\nAbsolute paths work too.": "",
        "The Embedding (eg textual inversion) model folder to use within 'ModelRoot'.\nDefaults to 'Embeddings'.\nAbsolute paths work too.": "",
        "The folder for wildcard (.txt) files, under Data.\nDefaults to 'Wildcards'": "",
        "The format for parameter hints to display as.\nDefault is 'BUTTON'.": "",
        "The FPS (frames per second) to use for video generation.\nThis configures the target FPS the video will try to generate for.": "",
        "The image to use as the input to ControlNet guidance.\nThis image will be preprocessed by the chosen preprocessor.\nIf ControlNet is enabled, but this input is not, Init Image will be used instead.": "",
        "The input prompt text that describes the image you want to generate.\nTell the AI what you want to see.": "",
        "The LoRA (or related adapter type) model folder to use within 'ModelRoot'.\nDefaults to 'Lora'.\nAbsolute paths work too.": "",
        "The maximum duration an individual request can be waiting on a backend to be available before giving up.\nNot to be confused with 'MaxTimeoutMinutes' which requires backends be unresponsive for that duration, this duration includes requests that are merely waiting because other requests are queued.\nDefaults to 60 * 24 * 7 = 1 week (ultra-long max queue duration).": "",
        "The maximum number of pending requests to continue forcing orderly processing of.\nOver this limit, requests may start going out of order.": "",
        "The minimum CFG to use for video generation.\nVideos start with max CFG on first frame, and then reduce to this CFG. Set to -1 to disable.": "",
        "The minimum tier of logs that should be visible in the console.\nDefault is 'info'.": "",
        "The model folder to use within 'ModelRoot'.\nDefaults to 'Stable-Diffusion'.\nAbsolute paths work too.": "",
        "The model to use for refinement. This should be a model that's good at small-details, and use a structural model as your base model.\n'Use Base' will use your base model rather than switching.\nSDXL 1.0 released with an official refiner model.": "",
        "The model to use for video generation.\nThis should be an SVD (Stable Video Diffusion) model.\nNote that SVD favors a low CFG (~2.5).": "",
        "The preprocessor to use on the ControlNet input image.\nIf toggled off, will be automatically selected.\nUse 'None' to disable preprocessing.": "",
        "The server has updated since you opened the page, please refresh.": "",
        "The size of hypertiles to use for the refining stage.\nHyperTile is a technique to speed up sampling of large images by tiling the image and batching the tiles.\nThis is useful when using SDv1 models as the refiner. SDXL-Base models do not benefit as much.": "",
        "The VAE (autoencoder) model folder to use within 'ModelRoot'.\nDefaults to 'VAE'.\nAbsolute paths work too.": "",
        "The VAE (Variational Auto-Encoder) controls the translation between images and latent space.\nIf your images look faded out, or glitched, you may have the wrong VAE.\nAll models have a VAE baked in by default, this option lets you swap to a different one if you want to.": "",
        "Theme": "",
        "This server is likely accessible from LAN on one of the following addresses:": "",
        "Thumbnails": "",
        "Tools": "",
        "ugly, bad, gross": "",
        "UI": "",
        "Unsampler Prompt": "",
        "Upload Preset File (JSON or CSV)": "",
        "Use As ControlNet Input": "",
        "Use As Init": "",
        "Use As ReVision": "",
        "Use IP-Adapter": "",
        "Use IP-Adapter for ReVision input handling.": "",
        "User": "",
        "User Info": "",
        "User Settings": "",
        "Utilities": "",
        "VAE": "",
        "VAE Tile Size": "",
        "VAEs": "",
        "Variation Seed": "",
        "Variation Seed Strength": "",
        "Video": "",
        "Video Augmentation Level": "",
        "Video CFG": "",
        "Video Format": "",
        "Video FPS": "",
        "Video Frames": "",
        "Video Min CFG": "",
        "Video Model": "",
        "Video Motion Bucket": "",
        "Video Preview Type": "",
        "Video Steps": "",
        "Webhook to call (empty JSON POST) when all queues are done and the server is going idle.\nLeave empty to disable any webhook.\nCall must return before queuing may restart.": "",
        "Webhook to call (empty JSON POST) when queues are starting up from idle.\nLeave empty to disable any webhook.\nCall must return before the first generation starts.": "",
        "WebHooks": "",
        "Weight to use with IP-Adapter (if enabled).": "",
        "Weight values for the LoRA model list.": "",
        "What custom workflow to use in ComfyUI (built in the Comfy Workflow Editor tab)": "",
        "What format to save images in.\nDefault is '.jpg' (at 100% quality).": "",
        "What format to save videos in.": "",
        "What hand-written specialty workflow to use in ComfyUI (files in 'Workflows' folder within the ComfyUI extension)": "",
        "What language to display the UI in.\nDefault is 'en' (English).": "",
        "What layer of CLIP to stop at, from the end.\nAlso known as 'CLIP Skip'. Default CLIP Skip is -1, some models prefer -2.\nSDv2, SDXL, and beyond do not need this set ever.": "",
        "What main checkpoint model should be used.": "",
        "What models are allowed, as a path regex.\nDirectory-separator is always '/'. Can be '.*' for all, 'MyFolder/.*' for only within that folder, etc.\nDefault is all.": "",
        "What theme to use. Default is 'dark_dreams'.": "",
        "What VAE to use with SDv1 models by default. Use 'None' to use the one in the model.": "",
        "What VAE to use with SDXL models by default. Use 'None' to use the one in the model.": "",
        "What web host address to use. `localhost` means your PC only.\nLinux users may use `0.0.0.0` to mean accessible to anyone that can connect to your PC (ie LAN users, or the public if your firewall is open).\nWindows users may use `*` for that, though it may require additional Windows firewall configuration.\nAdvanced server users may wish to manually specify a host bind address here.": "",
        "What web port to use. Default is '7801'.": "",
        "When enabled, the normal width parameter is used, and this value is multiplied by the width to derive the image height.": "",
        "When generating live previews, this is how many simultaneous generation requests can be waiting at one time.": "",
        "When to start applying controlnet, as a fraction of steps.\nFor example, 0.5 starts applying halfway through. Must be less than End.\nExcluding early steps reduces the controlnet's impact on overall image structure.": "",
        "When to stop applying controlnet, as a fraction of steps.\nFor example, 0.5 stops applying halfway through. Must be greater than Start.\nExcluding later steps reduces the controlnet's impact on finer details.": "",
        "When true, output paths always have the username as a folder.\nWhen false, this will be skipped.\nKeep this on in multi-user environments.": "",
        "When using regionalized prompts with distinct 'object' values, this overrides the model used to inpaint those objects.": "",
        "When using regionalized prompts, this factor controls how strongly the global prompt overrides the regional prompts.\n0 means ignore global prompt, 1 means ignore regional, 0.5 means half-n-half.": "",
        "Whether to store metadata into saved images.\nDefaults enabled.": "",
        "Whether your files save to server data drive or not.": "",
        "Which models to apply FreeU to, as base, refiner, or both. Irrelevant when not using refiner.": "",
        "Which StableSwarmUI backend type should be used for this request.": "",
        "Which trained 'motion bucket' to use for the video model.\nHigher values induce more motion. Most values should stay in the 100-200 range.\n127 is a good baseline.": "",
        "Which user-settings the user is allowed to modify.\nDefault is all of them.": "",
        "Width": "",
        "Wildcard Seed": "",
        "Wildcard selection seed.\nIf enabled, this seed will be used for selecting entries from wildcards.\nIf disabled, the image seed will be used.\n-1 = random.": "",
        "Wildcards": "",
        "Wildcards are lists of random prompt segments. One entry per line. Prompt sub-syntax is allowed (eg you can link another wildcard, or use <random:...>, or <preset:...> or anything else you want).": "",
        "WildcardsFolder": "",
        "Zeroes the prompt and negative prompt for ReVision inputs.\nApplies only to the base, the refiner will still get prompts.\nIf you want zeros on both, just delete your prompt text.\nIf not checked, empty prompts will be zeroed regardless.": ""
    }
}
